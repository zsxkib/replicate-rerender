{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a889add4899d40dcabba75b4223c7b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_841d36484e2c48708b391bea486cd749",
              "IPY_MODEL_9f83cd209d524d25a9d7ec049cf11c66",
              "IPY_MODEL_0bc7601f297b473fa1e03b83bc614e38"
            ],
            "layout": "IPY_MODEL_c66d81c9f2c04a70b88552e1ad5712f4"
          }
        },
        "841d36484e2c48708b391bea486cd749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e48393a20b2e482c929abd3689919281",
            "placeholder": "​",
            "style": "IPY_MODEL_332c7a06f647421193b50cbaedcdaa5d",
            "value": "Downloading (…)_sintel-0c07dcb3.pth: 100%"
          }
        },
        "9f83cd209d524d25a9d7ec049cf11c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b2dff2ea1b845e4adc3cd6e3058405e",
            "max": 18768907,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70bcf9cfe849411db33808301dc085d4",
            "value": 18768907
          }
        },
        "0bc7601f297b473fa1e03b83bc614e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d61a0abc573545f682002a941eb9e26f",
            "placeholder": "​",
            "style": "IPY_MODEL_b81c20954bb64363b84693db1ae07530",
            "value": " 18.8M/18.8M [00:00&lt;00:00, 141MB/s]"
          }
        },
        "c66d81c9f2c04a70b88552e1ad5712f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e48393a20b2e482c929abd3689919281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "332c7a06f647421193b50cbaedcdaa5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b2dff2ea1b845e4adc3cd6e3058405e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70bcf9cfe849411db33808301dc085d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d61a0abc573545f682002a941eb9e26f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b81c20954bb64363b84693db1ae07530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f2d20f0600246edbf89b561fc691054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_365d60d73635470d8485b054a18ef550",
              "IPY_MODEL_6a3434c14f7a4d288864827ad0f8f0a1",
              "IPY_MODEL_456489aac79442f584915abeac785e91"
            ],
            "layout": "IPY_MODEL_87a8b5b757b64ce884d61e65c24b00aa"
          }
        },
        "365d60d73635470d8485b054a18ef550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8acbca6149cc4bd5a8a965fcea9e4775",
            "placeholder": "​",
            "style": "IPY_MODEL_6379ccec590142288b0120cb48f9972f",
            "value": "Downloading (…)shooters-7322716.mp4: 100%"
          }
        },
        "6a3434c14f7a4d288864827ad0f8f0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad610af2a66e4103b0118ea255649924",
            "max": 2799784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dce77207dcf947e9b6f1f86c648c145c",
            "value": 2799784
          }
        },
        "456489aac79442f584915abeac785e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075eca3468bc403b9cbb15836df9cd69",
            "placeholder": "​",
            "style": "IPY_MODEL_c28ba7f3ea314f79964e7767c9da91c5",
            "value": " 2.80M/2.80M [00:00&lt;00:00, 31.1MB/s]"
          }
        },
        "87a8b5b757b64ce884d61e65c24b00aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8acbca6149cc4bd5a8a965fcea9e4775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6379ccec590142288b0120cb48f9972f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad610af2a66e4103b0118ea255649924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce77207dcf947e9b6f1f86c648c145c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "075eca3468bc403b9cbb15836df9cd69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c28ba7f3ea314f79964e7767c9da91c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fd50b2af0664d338b0f54150c0a7167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a312edfddce4d7bbd105aa87efcd952",
              "IPY_MODEL_93faa37d6b8f465ab796fa2c1781d68e",
              "IPY_MODEL_e1530746fb1f40f2b3f83abbbfd6154c"
            ],
            "layout": "IPY_MODEL_8b4b906d0b65455683115e8113ffe5f6"
          }
        },
        "1a312edfddce4d7bbd105aa87efcd952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_258a9642541d44fdaae671097df4c8bb",
            "placeholder": "​",
            "style": "IPY_MODEL_0b4baa27ba1349109ad02d0b01b91520",
            "value": "Downloading (…)92-540x960-25fps.mp4: 100%"
          }
        },
        "93faa37d6b8f465ab796fa2c1781d68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e0653648b44284a0faf328365f5722",
            "max": 1597192,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02443e9520b649fa80f6a8438ec1ff90",
            "value": 1597192
          }
        },
        "e1530746fb1f40f2b3f83abbbfd6154c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24781cb119774426afdc2de549e6b2a7",
            "placeholder": "​",
            "style": "IPY_MODEL_add84a85aa51477088da7bb66b6202f9",
            "value": " 1.60M/1.60M [00:00&lt;00:00, 35.5MB/s]"
          }
        },
        "8b4b906d0b65455683115e8113ffe5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258a9642541d44fdaae671097df4c8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4baa27ba1349109ad02d0b01b91520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70e0653648b44284a0faf328365f5722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02443e9520b649fa80f6a8438ec1ff90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24781cb119774426afdc2de549e6b2a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add84a85aa51477088da7bb66b6202f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f094839c9df41dca8218f7729fd8068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b028c38d488452b8aa2344f46599dd5",
              "IPY_MODEL_4713ef62461f408692ada75f299989a5",
              "IPY_MODEL_f0ea771136874cda915472facb803b1d"
            ],
            "layout": "IPY_MODEL_9f4c9a55e4a944aabe475ceff139cd85"
          }
        },
        "5b028c38d488452b8aa2344f46599dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2749560d53432294faafa64d2fea36",
            "placeholder": "​",
            "style": "IPY_MODEL_194e00f5b8d34010b89a6b13f4d4d23c",
            "value": "Downloading (…)32-960x506-25fps.mp4: 100%"
          }
        },
        "4713ef62461f408692ada75f299989a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72b86fccc7847a8ab55afcd3c05ec29",
            "max": 673304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1803e1550c942df92bff485038991b7",
            "value": 673304
          }
        },
        "f0ea771136874cda915472facb803b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca48d5e6595c4af096e6f807998f859f",
            "placeholder": "​",
            "style": "IPY_MODEL_e2d85c312c1e4580814652ca9a28f381",
            "value": " 673k/673k [00:00&lt;00:00, 14.4MB/s]"
          }
        },
        "9f4c9a55e4a944aabe475ceff139cd85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2749560d53432294faafa64d2fea36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194e00f5b8d34010b89a6b13f4d4d23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e72b86fccc7847a8ab55afcd3c05ec29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1803e1550c942df92bff485038991b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca48d5e6595c4af096e6f807998f859f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d85c312c1e4580814652ca9a28f381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs34Y8J1d9KV",
        "outputId": "e85ef841-4e6f-42ad-dced-2cd2efc22940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'replicate-rerender' already exists and is not an empty directory.\n",
            "/content/replicate-rerender\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: basicsr in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: blendmodes in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2022)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.35.2)\n",
            "Requirement already satisfied: invisible-watermark in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.1.5)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.6.12)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.3.0)\n",
            "Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.20.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.0.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.3.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.24.0)\n",
            "Requirement already satisfied: streamlit-drawable-canvas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.9.3)\n",
            "Requirement already satisfied: test-tube in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.7.5)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.9.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.11.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.30.2)\n",
            "Requirement already satisfied: webdataset in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.2.48)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (0.40.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (0.18.3)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (9.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (1.10.1)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (2.14.0a20230629)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from basicsr->-r requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: aenum<4,>=3.1.7 in /usr/local/lib/python3.10/dist-packages (from blendmodes->-r requirements.txt (line 3)) (3.1.15)\n",
            "Requirement already satisfied: deprecation<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from blendmodes->-r requirements.txt (line 3)) (2.1.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (23.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (0.98.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (0.3.0)\n",
            "Requirement already satisfied: gradio-client>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (0.2.7)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (0.15.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (0.3.3)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (1.5.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (1.10.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (0.25.1)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (2.14.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (0.0.6)\n",
            "Requirement already satisfied: semantic-version in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (2.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (11.0.3)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from invisible-watermark->-r requirements.txt (line 6)) (1.14.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from invisible-watermark->-r requirements.txt (line 6)) (1.15.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark->-r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia->-r requirements.txt (line 7)) (23.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf->-r requirements.txt (line 8)) (4.9.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch->-r requirements.txt (line 9)) (2022.10.31)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open_clip_torch->-r requirements.txt (line 9)) (6.1.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from open_clip_torch->-r requirements.txt (line 9)) (0.1.99)\n",
            "Requirement already satisfied: protobuf<4 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch->-r requirements.txt (line 9)) (3.20.3)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 10)) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 10)) (4.6.3)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 10)) (0.8.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (1.6.2)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (6.7.0)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (9.0.0)\n",
            "Requirement already satisfied: pympler<2,>=0.9 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: rich<14,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (13.4.2)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (8.2.2)\n",
            "Requirement already satisfied: toml<2 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<5,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (4.3.1)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.20.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (3.1.31)\n",
            "Requirement already satisfied: pydeck<1,>=0.1.dev5 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (6.3.1)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 12)) (3.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from test-tube->-r requirements.txt (line 14)) (2.25.1)\n",
            "Requirement already satisfied: tensorboard>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from test-tube->-r requirements.txt (line 14)) (2.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 17)) (3.12.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 17)) (0.13.3)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset->-r requirements.txt (line 18)) (0.1.7)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->-r requirements.txt (line 19)) (3.7.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->-r requirements.txt (line 19)) (2.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 5)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 5)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 5)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 5)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 5)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3->streamlit->-r requirements.txt (line 12)) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit->-r requirements.txt (line 12)) (3.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio->-r requirements.txt (line 5)) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2->streamlit->-r requirements.txt (line 12)) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr->-r requirements.txt (line 2)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr->-r requirements.txt (line 2)) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (3.4.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (0.40.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr->-r requirements.txt (line 2)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr->-r requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->basicsr->-r requirements.txt (line 2)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->basicsr->-r requirements.txt (line 2)) (16.0.6)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal<5,>=1.1->streamlit->-r requirements.txt (line 12)) (0.1.0.post0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators<1,>=0.2->streamlit->-r requirements.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r requirements.txt (line 5)) (0.27.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 9)) (0.2.6)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 5)) (0.17.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 5)) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime->invisible-watermark->-r requirements.txt (line 6)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->invisible-watermark->-r requirements.txt (line 6)) (23.5.26)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr->-r requirements.txt (line 2)) (2023.4.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit->-r requirements.txt (line 12)) (5.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (1.3.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 5)) (3.7.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 5)) (0.19.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 5)) (1.0.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime->invisible-watermark->-r requirements.txt (line 6)) (10.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit->-r requirements.txt (line 12)) (2023.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->basicsr->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 5)) (1.1.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15.0->test-tube->-r requirements.txt (line 14)) (3.2.2)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.22.4)\n",
            "Requirement already satisfied: pyre-extensions==0.0.29 in /usr/local/lib/python3.10/dist-packages (from xformers) (0.0.29)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->xformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->xformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->xformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->xformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyre-extensions==0.0.29->xformers) (1.0.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.12.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from triton) (2.0.1+cu118)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton) (16.0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->triton) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->triton) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->triton) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->triton) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->triton) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->triton) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/zsxkib/replicate-rerender.git\n",
        "%cd /content/replicate-rerender\n",
        "!pip install -r requirements.txt -U\n",
        "# !python app.py\n",
        "!pip install xformers\n",
        "!pip install triton\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from enum import Enum\n",
        "\n",
        "import cv2\n",
        "import einops\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from blendmodes.blend import BlendType, blendLayers\n",
        "from PIL import Image\n",
        "from pytorch_lightning import seed_everything\n",
        "from safetensors.torch import load_file\n",
        "from skimage import exposure\n",
        "\n",
        "import src.import_util  # noqa: F401\n",
        "from ControlNet.annotator.canny import CannyDetector\n",
        "from ControlNet.annotator.hed import HEDdetector\n",
        "from ControlNet.annotator.util import HWC3\n",
        "from ControlNet.cldm.model import create_model, load_state_dict\n",
        "from gmflow_module.gmflow.gmflow import GMFlow\n",
        "from flow.flow_utils import get_warped_and_mask\n",
        "from sd_model_cfg import model_dict\n",
        "from src.config import RerenderConfig\n",
        "from src.controller import AttentionControl\n",
        "from src.ddim_v_hacked import DDIMVSampler\n",
        "from src.img_util import find_flat_region, numpy2tensor\n",
        "from src.video_util import (frame_to_video, get_fps, get_frame_count,\n",
        "                            prepare_frames)\n",
        "\n",
        "import huggingface_hub\n",
        "\n",
        "repo_name = 'Anonymous-sub/Rerender'\n",
        "\n",
        "huggingface_hub.hf_hub_download(repo_name,\n",
        "                                'pexels-koolshooters-7322716.mp4',\n",
        "                                local_dir='videos')\n",
        "huggingface_hub.hf_hub_download(\n",
        "    repo_name,\n",
        "    'pexels-antoni-shkraba-8048492-540x960-25fps.mp4',\n",
        "    local_dir='videos')\n",
        "huggingface_hub.hf_hub_download(\n",
        "    repo_name,\n",
        "    'pexels-cottonbro-studio-6649832-960x506-25fps.mp4',\n",
        "    local_dir='videos')\n",
        "\n",
        "inversed_model_dict = dict()\n",
        "for k, v in model_dict.items():\n",
        "    inversed_model_dict[v] = k\n",
        "\n",
        "to_tensor = T.PILToTensor()\n",
        "blur = T.GaussianBlur(kernel_size=(9, 9), sigma=(18, 18))\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "class ProcessingState(Enum):\n",
        "    NULL = 0\n",
        "    FIRST_IMG = 1\n",
        "    KEY_IMGS = 2\n",
        "\n",
        "\n",
        "MAX_KEYFRAME = 300\n",
        "\n",
        "\n",
        "class GlobalState:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.sd_model = None\n",
        "        self.ddim_v_sampler = None\n",
        "        self.detector_type = None\n",
        "        self.detector = None\n",
        "        self.controller = None\n",
        "        self.processing_state = ProcessingState.NULL\n",
        "        flow_model = GMFlow(\n",
        "            feature_channels=128,\n",
        "            num_scales=1,\n",
        "            upsample_factor=8,\n",
        "            num_head=1,\n",
        "            attention_type='swin',\n",
        "            ffn_dim_expansion=4,\n",
        "            num_transformer_layers=6,\n",
        "        ).to(device)\n",
        "\n",
        "        checkpoint = torch.load('models/gmflow_sintel-0c07dcb3.pth',\n",
        "                                map_location=lambda storage, loc: storage)\n",
        "        weights = checkpoint['model'] if 'model' in checkpoint else checkpoint\n",
        "        flow_model.load_state_dict(weights, strict=False)\n",
        "        flow_model.eval()\n",
        "        self.flow_model = flow_model\n",
        "\n",
        "    def update_controller(self, inner_strength, mask_period, cross_period,\n",
        "                          ada_period, warp_period):\n",
        "        self.controller = AttentionControl(inner_strength, mask_period,\n",
        "                                           cross_period, ada_period,\n",
        "                                           warp_period)\n",
        "\n",
        "    def update_sd_model(self, sd_model, control_type):\n",
        "        if sd_model == self.sd_model:\n",
        "            return\n",
        "        self.sd_model = sd_model\n",
        "        model = create_model('./ControlNet/models/cldm_v15.yaml').cpu()\n",
        "        if control_type == 'HED':\n",
        "            model.load_state_dict(\n",
        "                load_state_dict(huggingface_hub.hf_hub_download(\n",
        "                    'lllyasviel/ControlNet', './models/control_sd15_hed.pth'),\n",
        "                                location=device))\n",
        "        elif control_type == 'canny':\n",
        "            model.load_state_dict(\n",
        "                load_state_dict(huggingface_hub.hf_hub_download(\n",
        "                    'lllyasviel/ControlNet', 'models/control_sd15_canny.pth'),\n",
        "                                location=device))\n",
        "        model.to(device)\n",
        "        sd_model_path = model_dict[sd_model]\n",
        "        if len(sd_model_path) > 0:\n",
        "            model_ext = os.path.splitext(sd_model_path)[1]\n",
        "            downloaded_model = huggingface_hub.hf_hub_download(\n",
        "                repo_name, sd_model_path)\n",
        "            if model_ext == '.safetensors':\n",
        "                model.load_state_dict(load_file(downloaded_model),\n",
        "                                      strict=False)\n",
        "            elif model_ext == '.ckpt' or model_ext == '.pth':\n",
        "                model.load_state_dict(\n",
        "                    torch.load(downloaded_model)['state_dict'], strict=False)\n",
        "\n",
        "        try:\n",
        "            model.first_stage_model.load_state_dict(torch.load(\n",
        "                huggingface_hub.hf_hub_download(\n",
        "                    'stabilityai/sd-vae-ft-mse-original',\n",
        "                    'vae-ft-mse-840000-ema-pruned.ckpt'))['state_dict'],\n",
        "                                                    strict=False)\n",
        "        except Exception:\n",
        "            print('Warning: We suggest you download the fine-tuned VAE',\n",
        "                  'otherwise the generation quality will be degraded')\n",
        "\n",
        "        self.ddim_v_sampler = DDIMVSampler(model)\n",
        "\n",
        "    def clear_sd_model(self):\n",
        "        self.sd_model = None\n",
        "        self.ddim_v_sampler = None\n",
        "        if device == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    def update_detector(self, control_type, canny_low=100, canny_high=200):\n",
        "        if self.detector_type == control_type:\n",
        "            return\n",
        "        if control_type == 'HED':\n",
        "            self.detector = HEDdetector()\n",
        "        elif control_type == 'canny':\n",
        "            canny_detector = CannyDetector()\n",
        "            low_threshold = canny_low\n",
        "            high_threshold = canny_high\n",
        "\n",
        "            def apply_canny(x):\n",
        "                return canny_detector(x, low_threshold, high_threshold)\n",
        "\n",
        "            self.detector = apply_canny\n",
        "\n",
        "\n",
        "global_state = GlobalState()\n",
        "global_video_path = None\n",
        "video_frame_count = None\n",
        "\n",
        "\n",
        "def create_cfg(input_path, prompt, image_resolution, control_strength,\n",
        "               color_preserve, left_crop, right_crop, top_crop, bottom_crop,\n",
        "               control_type, low_threshold, high_threshold, ddim_steps, scale,\n",
        "               seed, sd_model, a_prompt, n_prompt, interval, keyframe_count,\n",
        "               x0_strength, use_constraints, cross_start, cross_end,\n",
        "               style_update_freq, warp_start, warp_end, mask_start, mask_end,\n",
        "               ada_start, ada_end, mask_strength, inner_strength,\n",
        "               smooth_boundary):\n",
        "    use_warp = 'shape-aware fusion' in use_constraints\n",
        "    use_mask = 'pixel-aware fusion' in use_constraints\n",
        "    use_ada = 'color-aware AdaIN' in use_constraints\n",
        "\n",
        "    if not use_warp:\n",
        "        warp_start = 1\n",
        "        warp_end = 0\n",
        "\n",
        "    if not use_mask:\n",
        "        mask_start = 1\n",
        "        mask_end = 0\n",
        "\n",
        "    if not use_ada:\n",
        "        ada_start = 1\n",
        "        ada_end = 0\n",
        "\n",
        "    input_name = os.path.split(input_path)[-1].split('.')[0]\n",
        "    frame_count = 2 + keyframe_count * interval\n",
        "    cfg = RerenderConfig()\n",
        "    cfg.create_from_parameters(\n",
        "        input_path,\n",
        "        os.path.join('result', input_name, 'blend.mp4'),\n",
        "        prompt,\n",
        "        a_prompt=a_prompt,\n",
        "        n_prompt=n_prompt,\n",
        "        frame_count=frame_count,\n",
        "        interval=interval,\n",
        "        crop=[left_crop, right_crop, top_crop, bottom_crop],\n",
        "        sd_model=sd_model,\n",
        "        ddim_steps=ddim_steps,\n",
        "        scale=scale,\n",
        "        control_type=control_type,\n",
        "        control_strength=control_strength,\n",
        "        canny_low=low_threshold,\n",
        "        canny_high=high_threshold,\n",
        "        seed=seed,\n",
        "        image_resolution=image_resolution,\n",
        "        x0_strength=x0_strength,\n",
        "        style_update_freq=style_update_freq,\n",
        "        cross_period=(cross_start, cross_end),\n",
        "        warp_period=(warp_start, warp_end),\n",
        "        mask_period=(mask_start, mask_end),\n",
        "        ada_period=(ada_start, ada_end),\n",
        "        mask_strength=mask_strength,\n",
        "        inner_strength=inner_strength,\n",
        "        smooth_boundary=smooth_boundary,\n",
        "        color_preserve=color_preserve)\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def cfg_to_input(filename):\n",
        "\n",
        "    cfg = RerenderConfig()\n",
        "    cfg.create_from_path(filename)\n",
        "    keyframe_count = (cfg.frame_count - 2) // cfg.interval\n",
        "    use_constraints = [\n",
        "        'shape-aware fusion', 'pixel-aware fusion', 'color-aware AdaIN'\n",
        "    ]\n",
        "\n",
        "    sd_model = inversed_model_dict.get(cfg.sd_model, 'Stable Diffusion 1.5')\n",
        "\n",
        "    args = [\n",
        "        cfg.input_path, cfg.prompt, cfg.image_resolution, cfg.control_strength,\n",
        "        cfg.color_preserve, *cfg.crop, cfg.control_type, cfg.canny_low,\n",
        "        cfg.canny_high, cfg.ddim_steps, cfg.scale, cfg.seed, sd_model,\n",
        "        cfg.a_prompt, cfg.n_prompt, cfg.interval, keyframe_count,\n",
        "        cfg.x0_strength, use_constraints, *cfg.cross_period,\n",
        "        cfg.style_update_freq, *cfg.warp_period, *cfg.mask_period,\n",
        "        *cfg.ada_period, cfg.mask_strength, cfg.inner_strength,\n",
        "        cfg.smooth_boundary\n",
        "    ]\n",
        "    return args\n",
        "\n",
        "\n",
        "def setup_color_correction(image):\n",
        "    correction_target = cv2.cvtColor(np.asarray(image.copy()),\n",
        "                                     cv2.COLOR_RGB2LAB)\n",
        "    return correction_target\n",
        "\n",
        "\n",
        "def apply_color_correction(correction, original_image):\n",
        "    image = Image.fromarray(\n",
        "        cv2.cvtColor(\n",
        "            exposure.match_histograms(cv2.cvtColor(np.asarray(original_image),\n",
        "                                                   cv2.COLOR_RGB2LAB),\n",
        "                                      correction,\n",
        "                                      channel_axis=2),\n",
        "            cv2.COLOR_LAB2RGB).astype('uint8'))\n",
        "\n",
        "    image = blendLayers(image, original_image, BlendType.LUMINOSITY)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def process(*args):\n",
        "    first_frame = process1(*args)\n",
        "\n",
        "    keypath = process2(*args)\n",
        "\n",
        "    return first_frame, keypath\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def process0(*args):\n",
        "    global global_video_path\n",
        "    global_video_path = args[0]\n",
        "    return process(*args[1:])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def process1(*args):\n",
        "\n",
        "    global global_video_path\n",
        "    cfg = create_cfg(global_video_path, *args)\n",
        "    global global_state\n",
        "    global_state.update_sd_model(cfg.sd_model, cfg.control_type)\n",
        "    global_state.update_controller(cfg.inner_strength, cfg.mask_period,\n",
        "                                   cfg.cross_period, cfg.ada_period,\n",
        "                                   cfg.warp_period)\n",
        "    global_state.update_detector(cfg.control_type, cfg.canny_low,\n",
        "                                 cfg.canny_high)\n",
        "    global_state.processing_state = ProcessingState.FIRST_IMG\n",
        "\n",
        "    prepare_frames(cfg.input_path, cfg.input_dir, cfg.image_resolution,\n",
        "                   cfg.crop)\n",
        "\n",
        "    ddim_v_sampler = global_state.ddim_v_sampler\n",
        "    model = ddim_v_sampler.model\n",
        "    detector = global_state.detector\n",
        "    controller = global_state.controller\n",
        "    model.control_scales = [cfg.control_strength] * 13\n",
        "    model.to(device)\n",
        "\n",
        "    num_samples = 1\n",
        "    eta = 0.0\n",
        "    imgs = sorted(os.listdir(cfg.input_dir))\n",
        "    imgs = [os.path.join(cfg.input_dir, img) for img in imgs]\n",
        "\n",
        "    model.cond_stage_model.device = device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        frame = cv2.imread(imgs[0])\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        img = HWC3(frame)\n",
        "        H, W, C = img.shape\n",
        "\n",
        "        img_ = numpy2tensor(img)\n",
        "\n",
        "        def generate_first_img(img_, strength):\n",
        "            encoder_posterior = model.encode_first_stage(img_.to(device))\n",
        "            x0 = model.get_first_stage_encoding(encoder_posterior).detach()\n",
        "\n",
        "            detected_map = detector(img)\n",
        "            detected_map = HWC3(detected_map)\n",
        "\n",
        "            control = torch.from_numpy(\n",
        "                detected_map.copy()).float().to(device) / 255.0\n",
        "            control = torch.stack([control for _ in range(num_samples)], dim=0)\n",
        "            control = einops.rearrange(control, 'b h w c -> b c h w').clone()\n",
        "            cond = {\n",
        "                'c_concat': [control],\n",
        "                'c_crossattn': [\n",
        "                    model.get_learned_conditioning(\n",
        "                        [cfg.prompt + ', ' + cfg.a_prompt] * num_samples)\n",
        "                ]\n",
        "            }\n",
        "            un_cond = {\n",
        "                'c_concat': [control],\n",
        "                'c_crossattn':\n",
        "                [model.get_learned_conditioning([cfg.n_prompt] * num_samples)]\n",
        "            }\n",
        "            shape = (4, H // 8, W // 8)\n",
        "\n",
        "            controller.set_task('initfirst')\n",
        "            seed_everything(cfg.seed)\n",
        "\n",
        "            samples, _ = ddim_v_sampler.sample(\n",
        "                cfg.ddim_steps,\n",
        "                num_samples,\n",
        "                shape,\n",
        "                cond,\n",
        "                verbose=False,\n",
        "                eta=eta,\n",
        "                unconditional_guidance_scale=cfg.scale,\n",
        "                unconditional_conditioning=un_cond,\n",
        "                controller=controller,\n",
        "                x0=x0,\n",
        "                strength=strength)\n",
        "            x_samples = model.decode_first_stage(samples)\n",
        "            x_samples_np = (\n",
        "                einops.rearrange(x_samples, 'b c h w -> b h w c') * 127.5 +\n",
        "                127.5).cpu().numpy().clip(0, 255).astype(np.uint8)\n",
        "            return x_samples, x_samples_np\n",
        "\n",
        "        # When not preserve color, draw a different frame at first and use its\n",
        "        # color to redraw the first frame.\n",
        "        if not cfg.color_preserve:\n",
        "            first_strength = -1\n",
        "        else:\n",
        "            first_strength = 1 - cfg.x0_strength\n",
        "\n",
        "        x_samples, x_samples_np = generate_first_img(img_, first_strength)\n",
        "\n",
        "        if not cfg.color_preserve:\n",
        "            color_corrections = setup_color_correction(\n",
        "                Image.fromarray(x_samples_np[0]))\n",
        "            global_state.color_corrections = color_corrections\n",
        "            img_ = apply_color_correction(color_corrections,\n",
        "                                          Image.fromarray(img))\n",
        "            img_ = to_tensor(img_).unsqueeze(0)[:, :3] / 127.5 - 1\n",
        "            x_samples, x_samples_np = generate_first_img(\n",
        "                img_, 1 - cfg.x0_strength)\n",
        "\n",
        "        global_state.first_result = x_samples\n",
        "        global_state.first_img = img\n",
        "\n",
        "    Image.fromarray(x_samples_np[0]).save(\n",
        "        os.path.join(cfg.first_dir, 'first.jpg'))\n",
        "\n",
        "    return x_samples_np[0]\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def process2(*args):\n",
        "    global global_state\n",
        "    global global_video_path\n",
        "\n",
        "    if global_state.processing_state != ProcessingState.FIRST_IMG:\n",
        "        raise gr.Error('Please generate the first key image before generating'\n",
        "                       ' all key images')\n",
        "\n",
        "    cfg = create_cfg(global_video_path, *args)\n",
        "    global_state.update_sd_model(cfg.sd_model, cfg.control_type)\n",
        "    global_state.update_detector(cfg.control_type, cfg.canny_low,\n",
        "                                 cfg.canny_high)\n",
        "    global_state.processing_state = ProcessingState.KEY_IMGS\n",
        "\n",
        "    # reset key dir\n",
        "    shutil.rmtree(cfg.key_dir)\n",
        "    os.makedirs(cfg.key_dir, exist_ok=True)\n",
        "\n",
        "    ddim_v_sampler = global_state.ddim_v_sampler\n",
        "    model = ddim_v_sampler.model\n",
        "    detector = global_state.detector\n",
        "    controller = global_state.controller\n",
        "    flow_model = global_state.flow_model\n",
        "    model.control_scales = [cfg.control_strength] * 13\n",
        "\n",
        "    num_samples = 1\n",
        "    eta = 0.0\n",
        "    firstx0 = True\n",
        "    pixelfusion = cfg.use_mask\n",
        "    imgs = sorted(os.listdir(cfg.input_dir))\n",
        "    imgs = [os.path.join(cfg.input_dir, img) for img in imgs]\n",
        "\n",
        "    first_result = global_state.first_result\n",
        "    first_img = global_state.first_img\n",
        "    pre_result = first_result\n",
        "    pre_img = first_img\n",
        "\n",
        "    for i in range(0, cfg.frame_count - 1, cfg.interval):\n",
        "        cid = i + 1\n",
        "        frame = cv2.imread(imgs[i + 1])\n",
        "        print(cid)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        img = HWC3(frame)\n",
        "        H, W, C = img.shape\n",
        "\n",
        "        if cfg.color_preserve or global_state.color_corrections is None:\n",
        "            img_ = numpy2tensor(img)\n",
        "        else:\n",
        "            img_ = apply_color_correction(global_state.color_corrections,\n",
        "                                          Image.fromarray(img))\n",
        "            img_ = to_tensor(img_).unsqueeze(0)[:, :3] / 127.5 - 1\n",
        "        encoder_posterior = model.encode_first_stage(img_.to(device))\n",
        "        x0 = model.get_first_stage_encoding(encoder_posterior).detach()\n",
        "\n",
        "        detected_map = detector(img)\n",
        "        detected_map = HWC3(detected_map)\n",
        "\n",
        "        control = torch.from_numpy(\n",
        "            detected_map.copy()).float().to(device) / 255.0\n",
        "        control = torch.stack([control for _ in range(num_samples)], dim=0)\n",
        "        control = einops.rearrange(control, 'b h w c -> b c h w').clone()\n",
        "        cond = {\n",
        "            'c_concat': [control],\n",
        "            'c_crossattn': [\n",
        "                model.get_learned_conditioning(\n",
        "                    [cfg.prompt + ', ' + cfg.a_prompt] * num_samples)\n",
        "            ]\n",
        "        }\n",
        "        un_cond = {\n",
        "            'c_concat': [control],\n",
        "            'c_crossattn':\n",
        "            [model.get_learned_conditioning([cfg.n_prompt] * num_samples)]\n",
        "        }\n",
        "        shape = (4, H // 8, W // 8)\n",
        "\n",
        "        cond['c_concat'] = [control]\n",
        "        un_cond['c_concat'] = [control]\n",
        "\n",
        "        image1 = torch.from_numpy(pre_img).permute(2, 0, 1).float()\n",
        "        image2 = torch.from_numpy(img).permute(2, 0, 1).float()\n",
        "        warped_pre, bwd_occ_pre, bwd_flow_pre = get_warped_and_mask(\n",
        "            flow_model, image1, image2, pre_result, False)\n",
        "        blend_mask_pre = blur(\n",
        "            F.max_pool2d(bwd_occ_pre, kernel_size=9, stride=1, padding=4))\n",
        "        blend_mask_pre = torch.clamp(blend_mask_pre + bwd_occ_pre, 0, 1)\n",
        "\n",
        "        image1 = torch.from_numpy(first_img).permute(2, 0, 1).float()\n",
        "        warped_0, bwd_occ_0, bwd_flow_0 = get_warped_and_mask(\n",
        "            flow_model, image1, image2, first_result, False)\n",
        "        blend_mask_0 = blur(\n",
        "            F.max_pool2d(bwd_occ_0, kernel_size=9, stride=1, padding=4))\n",
        "        blend_mask_0 = torch.clamp(blend_mask_0 + bwd_occ_0, 0, 1)\n",
        "\n",
        "        if firstx0:\n",
        "            mask = 1 - F.max_pool2d(blend_mask_0, kernel_size=8)\n",
        "            controller.set_warp(\n",
        "                F.interpolate(bwd_flow_0 / 8.0,\n",
        "                              scale_factor=1. / 8,\n",
        "                              mode='bilinear'), mask)\n",
        "        else:\n",
        "            mask = 1 - F.max_pool2d(blend_mask_pre, kernel_size=8)\n",
        "            controller.set_warp(\n",
        "                F.interpolate(bwd_flow_pre / 8.0,\n",
        "                              scale_factor=1. / 8,\n",
        "                              mode='bilinear'), mask)\n",
        "\n",
        "        controller.set_task('keepx0, keepstyle')\n",
        "        seed_everything(cfg.seed)\n",
        "        samples, intermediates = ddim_v_sampler.sample(\n",
        "            cfg.ddim_steps,\n",
        "            num_samples,\n",
        "            shape,\n",
        "            cond,\n",
        "            verbose=False,\n",
        "            eta=eta,\n",
        "            unconditional_guidance_scale=cfg.scale,\n",
        "            unconditional_conditioning=un_cond,\n",
        "            controller=controller,\n",
        "            x0=x0,\n",
        "            strength=1 - cfg.x0_strength)\n",
        "        direct_result = model.decode_first_stage(samples)\n",
        "\n",
        "        if not pixelfusion:\n",
        "            pre_result = direct_result\n",
        "            pre_img = img\n",
        "            viz = (\n",
        "                einops.rearrange(direct_result, 'b c h w -> b h w c') * 127.5 +\n",
        "                127.5).cpu().numpy().clip(0, 255).astype(np.uint8)\n",
        "\n",
        "        else:\n",
        "\n",
        "            blend_results = (1 - blend_mask_pre\n",
        "                             ) * warped_pre + blend_mask_pre * direct_result\n",
        "            blend_results = (\n",
        "                1 - blend_mask_0) * warped_0 + blend_mask_0 * blend_results\n",
        "\n",
        "            bwd_occ = 1 - torch.clamp(1 - bwd_occ_pre + 1 - bwd_occ_0, 0, 1)\n",
        "            blend_mask = blur(\n",
        "                F.max_pool2d(bwd_occ, kernel_size=9, stride=1, padding=4))\n",
        "            blend_mask = 1 - torch.clamp(blend_mask + bwd_occ, 0, 1)\n",
        "\n",
        "            encoder_posterior = model.encode_first_stage(blend_results)\n",
        "            xtrg = model.get_first_stage_encoding(\n",
        "                encoder_posterior).detach()  # * mask\n",
        "            blend_results_rec = model.decode_first_stage(xtrg)\n",
        "            encoder_posterior = model.encode_first_stage(blend_results_rec)\n",
        "            xtrg_rec = model.get_first_stage_encoding(\n",
        "                encoder_posterior).detach()\n",
        "            xtrg_ = (xtrg + 1 * (xtrg - xtrg_rec))  # * mask\n",
        "            blend_results_rec_new = model.decode_first_stage(xtrg_)\n",
        "            tmp = (abs(blend_results_rec_new - blend_results).mean(\n",
        "                dim=1, keepdims=True) > 0.25).float()\n",
        "            mask_x = F.max_pool2d((F.interpolate(tmp,\n",
        "                                                 scale_factor=1 / 8.,\n",
        "                                                 mode='bilinear') > 0).float(),\n",
        "                                  kernel_size=3,\n",
        "                                  stride=1,\n",
        "                                  padding=1)\n",
        "\n",
        "            mask = (1 - F.max_pool2d(1 - blend_mask, kernel_size=8)\n",
        "                    )  # * (1-mask_x)\n",
        "\n",
        "            if cfg.smooth_boundary:\n",
        "                noise_rescale = find_flat_region(mask)\n",
        "            else:\n",
        "                noise_rescale = torch.ones_like(mask)\n",
        "            masks = []\n",
        "            for i in range(cfg.ddim_steps):\n",
        "                if i <= cfg.ddim_steps * cfg.mask_period[\n",
        "                        0] or i >= cfg.ddim_steps * cfg.mask_period[1]:\n",
        "                    masks += [None]\n",
        "                else:\n",
        "                    masks += [mask * cfg.mask_strength]\n",
        "\n",
        "            # mask 3\n",
        "            # xtrg = ((1-mask_x) *\n",
        "            #         (xtrg + xtrg - xtrg_rec) + mask_x * samples) * mask\n",
        "            # mask 2\n",
        "            # xtrg = (xtrg + 1 * (xtrg - xtrg_rec)) * mask\n",
        "            xtrg = (xtrg + (1 - mask_x) * (xtrg - xtrg_rec)) * mask  # mask 1\n",
        "\n",
        "            tasks = 'keepstyle, keepx0'\n",
        "            if not firstx0:\n",
        "                tasks += ', updatex0'\n",
        "            if i % cfg.style_update_freq == 0:\n",
        "                tasks += ', updatestyle'\n",
        "            controller.set_task(tasks, 1.0)\n",
        "\n",
        "            seed_everything(cfg.seed)\n",
        "            samples, _ = ddim_v_sampler.sample(\n",
        "                cfg.ddim_steps,\n",
        "                num_samples,\n",
        "                shape,\n",
        "                cond,\n",
        "                verbose=False,\n",
        "                eta=eta,\n",
        "                unconditional_guidance_scale=cfg.scale,\n",
        "                unconditional_conditioning=un_cond,\n",
        "                controller=controller,\n",
        "                x0=x0,\n",
        "                strength=1 - cfg.x0_strength,\n",
        "                xtrg=xtrg,\n",
        "                mask=masks,\n",
        "                noise_rescale=noise_rescale)\n",
        "            x_samples = model.decode_first_stage(samples)\n",
        "            pre_result = x_samples\n",
        "            pre_img = img\n",
        "\n",
        "            viz = (einops.rearrange(x_samples, 'b c h w -> b h w c') * 127.5 +\n",
        "                   127.5).cpu().numpy().clip(0, 255).astype(np.uint8)\n",
        "\n",
        "        Image.fromarray(viz[0]).save(\n",
        "            os.path.join(cfg.key_dir, f'{cid:04d}.png'))\n",
        "\n",
        "    key_video_path = os.path.join(cfg.work_dir, 'key.mp4')\n",
        "    fps = get_fps(cfg.input_path)\n",
        "    fps //= cfg.interval\n",
        "    frame_to_video(key_video_path, cfg.key_dir, fps, False)\n",
        "\n",
        "    return key_video_path\n",
        "def input_uploaded(path):\n",
        "    frame_count = get_frame_count(path)\n",
        "    if frame_count <= 2:\n",
        "        raise AssertionError(\n",
        "            \"The input video is too short!\" \"Please input another video.\"\n",
        "        )\n",
        "\n",
        "    default_interval = min(10, frame_count - 2)\n",
        "    max_keyframe = min((frame_count - 2) // default_interval, MAX_KEYFRAME)\n",
        "\n",
        "    global video_frame_count\n",
        "    video_frame_count = frame_count\n",
        "    global global_video_path\n",
        "    global_video_path = path\n",
        "\n",
        "    # return gr.Slider.update(\n",
        "    #     value=default_interval, maximum=frame_count - 2\n",
        "    # ), gr.Slider.update(value=max_keyframe, maximum=max_keyframe)\n",
        "\n",
        "def input_changed(path):\n",
        "    frame_count = get_frame_count(path)\n",
        "    # if frame_count <= 2:\n",
        "    #     return gr.Slider.update(maximum=1), gr.Slider.update(maximum=1)\n",
        "\n",
        "    default_interval = min(10, frame_count - 2)\n",
        "    max_keyframe = min((frame_count - 2) // default_interval, MAX_KEYFRAME)\n",
        "\n",
        "    global video_frame_count\n",
        "    video_frame_count = frame_count\n",
        "    global global_video_path\n",
        "    global_video_path = path\n",
        "\n",
        "    # return gr.Slider.update(\n",
        "    #     value=default_interval, maximum=frame_count - 2\n",
        "    # ), gr.Slider.update(maximum=max_keyframe)\n",
        "\n",
        "def interval_changed(interval):\n",
        "    global video_frame_count\n",
        "    # if video_frame_count is None:\n",
        "    #     return gr.Slider.update()\n",
        "\n",
        "    max_keyframe = min((video_frame_count - 2) // interval, MAX_KEYFRAME)\n",
        "\n",
        "    # return gr.Slider.update(value=max_keyframe, maximum=max_keyframe)\n",
        "\n",
        "# DESCRIPTION = \"\"\"\n",
        "# ## Rerender A Video\n",
        "# ### This space provides the function of key frame translation. Full code for full video translation will be released upon the publication of the paper.\n",
        "# ### To avoid overload, we set limitations to the **maximum frame number** (8) and the maximum frame resolution (512x768).\n",
        "# ### The running time of a video of size 512x640 is about 1 minute per keyframe under T4 GPU.\n",
        "\n",
        "# ### How to use:\n",
        "# 1. **Run 1st Key Frame**: only translate the first frame, so you can adjust the prompts/models/parameters to find your ideal output appearance before run the whole video.\n",
        "# 2. **Run Key Frames**: translate all the key frames based on the settings of the first frame\n",
        "# 3. **Run All**: **Run 1st Key Frame** and **Run Key Frames**\n",
        "# 4. **Run Propagation**: propogate the key frames to other frames for full video translation. This part will be released upon the publication of the paper.\n",
        "\n",
        "# ### Tips:\n",
        "# 1. This method cannot handle large or quick motions where the optical flow is hard to estimate. **Videos with stable motions are preferred**.\n",
        "# 2. Pixel-aware fusion may not work for large or quick motions.\n",
        "# 3. Try different color-aware AdaIN settings and even unuse it to avoid color jittering.\n",
        "# 4. `revAnimated_v11` model for non-photorealstic style, `realisticVisionV20_v20` model for photorealstic style.\n",
        "# 5. To use your own SD/LoRA model, you may clone the space and specify your model with [sd_model_cfg.py](https://huggingface.co/spaces/Anonymous-sub/Rerender/blob/main/sd_model_cfg.py).\n",
        "# 6. This method is based on the original SD model. You may need to [convert](https://github.com/huggingface/diffusers/blob/main/scripts/convert_diffusers_to_original_stable_diffusion.py) Diffuser/Automatic1111 models to the original one.\n",
        "\n",
        "# **This code is for research purpose and non-commercial use only.**\n",
        "# \"\"\"\n",
        "\n",
        "# block = gr.Blocks().queue()\n",
        "# with block:\n",
        "#     with gr.Row():\n",
        "#         gr.Markdown(DESCRIPTION)\n",
        "#     with gr.Row():\n",
        "#         with gr.Column():\n",
        "#             input_path = gr.Video(\n",
        "#                 label=\"Input Video\", source=\"upload\", format=\"mp4\", visible=True\n",
        "#             )\n",
        "#             prompt = gr.Textbox(label=\"Prompt\")\n",
        "#             seed = gr.Slider(\n",
        "#                 label=\"Seed\",\n",
        "#                 minimum=0,\n",
        "#                 maximum=2147483647,\n",
        "#                 step=1,\n",
        "#                 value=0,\n",
        "#                 randomize=True,\n",
        "#             )\n",
        "#             run_button = gr.Button(value=\"Run All\")\n",
        "#             with gr.Row():\n",
        "#                 run_button1 = gr.Button(value=\"Run 1st Key Frame\")\n",
        "#                 run_button2 = gr.Button(value=\"Run Key Frames\")\n",
        "#                 run_button3 = gr.Button(value=\"Run Propagation\")\n",
        "#             with gr.Accordion(\n",
        "#                 \"Advanced options for the 1st frame translation\", open=False\n",
        "#             ):\n",
        "#                 image_resolution = gr.Slider(\n",
        "#                     label=\"Frame rsolution\",\n",
        "#                     minimum=256,\n",
        "#                     maximum=512,\n",
        "#                     value=512,\n",
        "#                     step=64,\n",
        "#                     info=\"To avoid overload, maximum 512\",\n",
        "#                 )\n",
        "#                 control_strength = gr.Slider(\n",
        "#                     label=\"ControNet strength\",\n",
        "#                     minimum=0.0,\n",
        "#                     maximum=2.0,\n",
        "#                     value=1.0,\n",
        "#                     step=0.01,\n",
        "#                 )\n",
        "#                 x0_strength = gr.Slider(\n",
        "#                     label=\"Denoising strength\",\n",
        "#                     minimum=0.00,\n",
        "#                     maximum=1.05,\n",
        "#                     value=0.75,\n",
        "#                     step=0.05,\n",
        "#                     info=(\n",
        "#                         \"0: fully recover the input.\" \"1.05: fully rerender the input.\"\n",
        "#                     ),\n",
        "#                 )\n",
        "#                 color_preserve = gr.Checkbox(\n",
        "#                     label=\"Preserve color\",\n",
        "#                     value=True,\n",
        "#                     info=\"Keep the color of the input video\",\n",
        "#                 )\n",
        "#                 with gr.Row():\n",
        "#                     left_crop = gr.Slider(\n",
        "#                         label=\"Left crop length\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=512,\n",
        "#                         value=0,\n",
        "#                         step=1,\n",
        "#                     )\n",
        "#                     right_crop = gr.Slider(\n",
        "#                         label=\"Right crop length\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=512,\n",
        "#                         value=0,\n",
        "#                         step=1,\n",
        "#                     )\n",
        "#                 with gr.Row():\n",
        "#                     top_crop = gr.Slider(\n",
        "#                         label=\"Top crop length\", minimum=0, maximum=512, value=0, step=1\n",
        "#                     )\n",
        "#                     bottom_crop = gr.Slider(\n",
        "#                         label=\"Bottom crop length\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=512,\n",
        "#                         value=0,\n",
        "#                         step=1,\n",
        "#                     )\n",
        "#                 with gr.Row():\n",
        "#                     control_type = gr.Dropdown(\n",
        "#                         [\"HED\", \"canny\"], label=\"Control type\", value=\"HED\"\n",
        "#                     )\n",
        "#                     low_threshold = gr.Slider(\n",
        "#                         label=\"Canny low threshold\",\n",
        "#                         minimum=1,\n",
        "#                         maximum=255,\n",
        "#                         value=100,\n",
        "#                         step=1,\n",
        "#                     )\n",
        "#                     high_threshold = gr.Slider(\n",
        "#                         label=\"Canny high threshold\",\n",
        "#                         minimum=1,\n",
        "#                         maximum=255,\n",
        "#                         value=200,\n",
        "#                         step=1,\n",
        "#                     )\n",
        "#                 ddim_steps = gr.Slider(\n",
        "#                     label=\"Steps\",\n",
        "#                     minimum=1,\n",
        "#                     maximum=20,\n",
        "#                     value=20,\n",
        "#                     step=1,\n",
        "#                     info=\"To avoid overload, maximum 20\",\n",
        "#                 )\n",
        "#                 scale = gr.Slider(\n",
        "#                     label=\"CFG scale\", minimum=0.1, maximum=30.0, value=7.5, step=0.1\n",
        "#                 )\n",
        "#                 sd_model_list = list(model_dict.keys())\n",
        "#                 sd_model = gr.Dropdown(\n",
        "#                     sd_model_list, label=\"Base model\", value=\"Stable Diffusion 1.5\"\n",
        "#                 )\n",
        "#                 a_prompt = gr.Textbox(\n",
        "#                     label=\"Added prompt\", value=\"best quality, extremely detailed\"\n",
        "#                 )\n",
        "#                 n_prompt = gr.Textbox(\n",
        "#                     label=\"Negative prompt\",\n",
        "#                     value=(\n",
        "#                         \"longbody, lowres, bad anatomy, bad hands, \"\n",
        "#                         \"missing fingers, extra digit, fewer digits, \"\n",
        "#                         \"cropped, worst quality, low quality\"\n",
        "#                     ),\n",
        "#                 )\n",
        "#             with gr.Accordion(\n",
        "#                 \"Advanced options for the key fame translation\", open=False\n",
        "#             ):\n",
        "#                 interval = gr.Slider(\n",
        "#                     label=\"Key frame frequency (K)\",\n",
        "#                     minimum=1,\n",
        "#                     maximum=1,\n",
        "#                     value=1,\n",
        "#                     step=1,\n",
        "#                     info=\"Uniformly sample the key frames every K frames\",\n",
        "#                 )\n",
        "#                 keyframe_count = gr.Slider(\n",
        "#                     label=\"Number of key frames\",\n",
        "#                     minimum=1,\n",
        "#                     maximum=1,\n",
        "#                     value=1,\n",
        "#                     step=1,\n",
        "#                     info=\"To avoid overload, maximum 8 key frames\",\n",
        "#                 )\n",
        "\n",
        "#                 use_constraints = (\n",
        "#                     gr.CheckboxGroup(\n",
        "#                         [\n",
        "#                             \"shape-aware fusion\",\n",
        "#                             \"pixel-aware fusion\",\n",
        "#                             \"color-aware AdaIN\",\n",
        "#                         ],\n",
        "#                         label=\"Select the cross-frame contraints to be used\",\n",
        "#                         value=[\n",
        "#                             \"shape-aware fusion\",\n",
        "#                             \"pixel-aware fusion\",\n",
        "#                             \"color-aware AdaIN\",\n",
        "#                         ],\n",
        "#                     ),\n",
        "#                 )\n",
        "#                 with gr.Row():\n",
        "#                     cross_start = gr.Slider(\n",
        "#                         label=\"Cross-frame attention start\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=1,\n",
        "#                         value=0,\n",
        "#                         step=0.05,\n",
        "#                     )\n",
        "#                     cross_end = gr.Slider(\n",
        "#                         label=\"Cross-frame attention end\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=1,\n",
        "#                         value=1,\n",
        "#                         step=0.05,\n",
        "#                     )\n",
        "#                 style_update_freq = gr.Slider(\n",
        "#                     label=\"Cross-frame attention update frequency\",\n",
        "#                     minimum=1,\n",
        "#                     maximum=100,\n",
        "#                     value=1,\n",
        "#                     step=1,\n",
        "#                     info=(\n",
        "#                         \"Update the key and value for \"\n",
        "#                         \"cross-frame attention every N key frames (recommend N*K>=10)\"\n",
        "#                     ),\n",
        "#                 )\n",
        "#                 with gr.Row():\n",
        "#                     warp_start = gr.Slider(\n",
        "#                         label=\"Shape-aware fusion start\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=1,\n",
        "#                         value=0,\n",
        "#                         step=0.05,\n",
        "#                     )\n",
        "#                     warp_end = gr.Slider(\n",
        "#                         label=\"Shape-aware fusion end\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=1,\n",
        "#                         value=0.1,\n",
        "#                         step=0.05,\n",
        "#                     )\n",
        "#                 with gr.Row():\n",
        "#                     mask_start = gr.Slider(\n",
        "#                         label=\"Pixel-aware fusion start\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=1,\n",
        "#                         value=0.5,\n",
        "#                         step=0.05,\n",
        "#                     )\n",
        "#                     mask_end = gr.Slider(\n",
        "#                         label=\"Pixel-aware fusion end\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=1,\n",
        "#                         value=0.8,\n",
        "#                         step=0.05,\n",
        "#                     )\n",
        "#                 with gr.Row():\n",
        "#                     ada_start = gr.Slider(\n",
        "#                         label=\"Color-aware AdaIN start\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=1,\n",
        "#                         value=0.8,\n",
        "#                         step=0.05,\n",
        "#                     )\n",
        "#                     ada_end = gr.Slider(\n",
        "#                         label=\"Color-aware AdaIN end\",\n",
        "#                         minimum=0,\n",
        "#                         maximum=1,\n",
        "#                         value=1,\n",
        "#                         step=0.05,\n",
        "#                     )\n",
        "#                 mask_strength = gr.Slider(\n",
        "#                     label=\"Pixel-aware fusion stength\",\n",
        "#                     minimum=0,\n",
        "#                     maximum=1,\n",
        "#                     value=0.5,\n",
        "#                     step=0.01,\n",
        "#                 )\n",
        "#                 inner_strength = gr.Slider(\n",
        "#                     label=\"Pixel-aware fusion detail level\",\n",
        "#                     minimum=0.5,\n",
        "#                     maximum=1,\n",
        "#                     value=0.9,\n",
        "#                     step=0.01,\n",
        "#                     info=\"Use a low value to prevent artifacts\",\n",
        "#                 )\n",
        "#                 smooth_boundary = gr.Checkbox(\n",
        "#                     label=\"Smooth fusion boundary\",\n",
        "#                     value=True,\n",
        "#                     info=\"Select to prevent artifacts at boundary\",\n",
        "#                 )\n",
        "\n",
        "#             with gr.Accordion(\"Example configs\", open=True):\n",
        "#                 config_dir = \"config\"\n",
        "#                 config_list = os.listdir(config_dir)\n",
        "#                 args_list = []\n",
        "#                 for config in config_list:\n",
        "#                     try:\n",
        "#                         config_path = os.path.join(config_dir, config)\n",
        "#                         args = cfg_to_input(config_path)\n",
        "#                         args_list.append(args)\n",
        "#                     except FileNotFoundError:\n",
        "#                         # The video file does not exist, skipped\n",
        "#                         pass\n",
        "\n",
        "#                 ips = [\n",
        "#                     prompt,\n",
        "#                     image_resolution,\n",
        "#                     control_strength,\n",
        "#                     color_preserve,\n",
        "#                     left_crop,\n",
        "#                     right_crop,\n",
        "#                     top_crop,\n",
        "#                     bottom_crop,\n",
        "#                     control_type,\n",
        "#                     low_threshold,\n",
        "#                     high_threshold,\n",
        "#                     ddim_steps,\n",
        "#                     scale,\n",
        "#                     seed,\n",
        "#                     sd_model,\n",
        "#                     a_prompt,\n",
        "#                     n_prompt,\n",
        "#                     interval,\n",
        "#                     keyframe_count,\n",
        "#                     x0_strength,\n",
        "#                     use_constraints[0],\n",
        "#                     cross_start,\n",
        "#                     cross_end,\n",
        "#                     style_update_freq,\n",
        "#                     warp_start,\n",
        "#                     warp_end,\n",
        "#                     mask_start,\n",
        "#                     mask_end,\n",
        "#                     ada_start,\n",
        "#                     ada_end,\n",
        "#                     mask_strength,\n",
        "#                     inner_strength,\n",
        "#                     smooth_boundary,\n",
        "#                 ]\n",
        "\n",
        "#         with gr.Column():\n",
        "#             result_image = gr.Image(\n",
        "#                 label=\"Output first frame\", type=\"numpy\", interactive=False\n",
        "#             )\n",
        "#             result_keyframe = gr.Video(\n",
        "#                 label=\"Output key frame video\", format=\"mp4\", interactive=False\n",
        "#             )\n",
        "#     with gr.Row():\n",
        "#         gr.Examples(\n",
        "#             examples=args_list,\n",
        "#             inputs=[input_path, *ips],\n",
        "#             fn=process0,\n",
        "#             outputs=[result_image, result_keyframe],\n",
        "#             cache_examples=False,\n",
        "#         )\n",
        "\n",
        "#     def input_uploaded(path):\n",
        "#         frame_count = get_frame_count(path)\n",
        "#         if frame_count <= 2:\n",
        "#             raise gr.Error(\n",
        "#                 \"The input video is too short!\" \"Please input another video.\"\n",
        "#             )\n",
        "\n",
        "#         default_interval = min(10, frame_count - 2)\n",
        "#         max_keyframe = min((frame_count - 2) // default_interval, MAX_KEYFRAME)\n",
        "\n",
        "#         global video_frame_count\n",
        "#         video_frame_count = frame_count\n",
        "#         global global_video_path\n",
        "#         global_video_path = path\n",
        "\n",
        "#         return gr.Slider.update(\n",
        "#             value=default_interval, maximum=frame_count - 2\n",
        "#         ), gr.Slider.update(value=max_keyframe, maximum=max_keyframe)\n",
        "\n",
        "#     def input_changed(path):\n",
        "#         frame_count = get_frame_count(path)\n",
        "#         if frame_count <= 2:\n",
        "#             return gr.Slider.update(maximum=1), gr.Slider.update(maximum=1)\n",
        "\n",
        "#         default_interval = min(10, frame_count - 2)\n",
        "#         max_keyframe = min((frame_count - 2) // default_interval, MAX_KEYFRAME)\n",
        "\n",
        "#         global video_frame_count\n",
        "#         video_frame_count = frame_count\n",
        "#         global global_video_path\n",
        "#         global_video_path = path\n",
        "\n",
        "#         return gr.Slider.update(\n",
        "#             value=default_interval, maximum=frame_count - 2\n",
        "#         ), gr.Slider.update(maximum=max_keyframe)\n",
        "\n",
        "#     def interval_changed(interval):\n",
        "#         global video_frame_count\n",
        "#         if video_frame_count is None:\n",
        "#             return gr.Slider.update()\n",
        "\n",
        "#         max_keyframe = min((video_frame_count - 2) // interval, MAX_KEYFRAME)\n",
        "\n",
        "#         return gr.Slider.update(value=max_keyframe, maximum=max_keyframe)\n",
        "\n",
        "#     input_path.change(input_changed, input_path, [interval, keyframe_count])\n",
        "#     input_path.upload(input_uploaded, input_path, [interval, keyframe_count])\n",
        "#     interval.change(interval_changed, interval, keyframe_count)\n",
        "\n",
        "#     run_button.click(fn=process, inputs=ips, outputs=[result_image, result_keyframe])\n",
        "#     run_button1.click(fn=process1, inputs=ips, outputs=[result_image])\n",
        "#     run_button2.click(fn=process2, inputs=ips, outputs=[result_keyframe])\n",
        "\n",
        "#     def process3():\n",
        "#         raise gr.Error(\n",
        "#             \"Coming Soon. Full code for full video translation will be \"\n",
        "#             \"released upon the publication of the paper.\"\n",
        "#         )\n",
        "\n",
        "#     run_button3.click(fn=process3, outputs=[result_keyframe])\n",
        "\n",
        "# block.queue(concurrency_count=1, max_size=20)\n",
        "# block.launch(server_name=\"0.0.0.0\", share=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274,
          "referenced_widgets": [
            "a889add4899d40dcabba75b4223c7b7a",
            "841d36484e2c48708b391bea486cd749",
            "9f83cd209d524d25a9d7ec049cf11c66",
            "0bc7601f297b473fa1e03b83bc614e38",
            "c66d81c9f2c04a70b88552e1ad5712f4",
            "e48393a20b2e482c929abd3689919281",
            "332c7a06f647421193b50cbaedcdaa5d",
            "8b2dff2ea1b845e4adc3cd6e3058405e",
            "70bcf9cfe849411db33808301dc085d4",
            "d61a0abc573545f682002a941eb9e26f",
            "b81c20954bb64363b84693db1ae07530",
            "7f2d20f0600246edbf89b561fc691054",
            "365d60d73635470d8485b054a18ef550",
            "6a3434c14f7a4d288864827ad0f8f0a1",
            "456489aac79442f584915abeac785e91",
            "87a8b5b757b64ce884d61e65c24b00aa",
            "8acbca6149cc4bd5a8a965fcea9e4775",
            "6379ccec590142288b0120cb48f9972f",
            "ad610af2a66e4103b0118ea255649924",
            "dce77207dcf947e9b6f1f86c648c145c",
            "075eca3468bc403b9cbb15836df9cd69",
            "c28ba7f3ea314f79964e7767c9da91c5",
            "1fd50b2af0664d338b0f54150c0a7167",
            "1a312edfddce4d7bbd105aa87efcd952",
            "93faa37d6b8f465ab796fa2c1781d68e",
            "e1530746fb1f40f2b3f83abbbfd6154c",
            "8b4b906d0b65455683115e8113ffe5f6",
            "258a9642541d44fdaae671097df4c8bb",
            "0b4baa27ba1349109ad02d0b01b91520",
            "70e0653648b44284a0faf328365f5722",
            "02443e9520b649fa80f6a8438ec1ff90",
            "24781cb119774426afdc2de549e6b2a7",
            "add84a85aa51477088da7bb66b6202f9",
            "1f094839c9df41dca8218f7729fd8068",
            "5b028c38d488452b8aa2344f46599dd5",
            "4713ef62461f408692ada75f299989a5",
            "f0ea771136874cda915472facb803b1d",
            "9f4c9a55e4a944aabe475ceff139cd85",
            "2d2749560d53432294faafa64d2fea36",
            "194e00f5b8d34010b89a6b13f4d4d23c",
            "e72b86fccc7847a8ab55afcd3c05ec29",
            "f1803e1550c942df92bff485038991b7",
            "ca48d5e6595c4af096e6f807998f859f",
            "e2d85c312c1e4580814652ca9a28f381"
          ]
        },
        "id": "TZbv9LF4rCiI",
        "outputId": "c083dd0a-cb4d-49af-e8ca-022303f46b72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logging improved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)_sintel-0c07dcb3.pth:   0%|          | 0.00/18.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a889add4899d40dcabba75b4223c7b7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)shooters-7322716.mp4:   0%|          | 0.00/2.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f2d20f0600246edbf89b561fc691054"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)92-540x960-25fps.mp4:   0%|          | 0.00/1.60M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fd50b2af0664d338b0f54150c0a7167"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)32-960x506-25fps.mp4:   0%|          | 0.00/673k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f094839c9df41dca8218f7729fd8068"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/replicate-rerender\n",
        "\n",
        "# model_dict = {\n",
        "#     'Stable Diffusion 1.5': '',\n",
        "#     'revAnimated_v11': 'models/revAnimated_v11.safetensors',\n",
        "#     'realisticVisionV20_v20': 'models/realisticVisionV20_v20.safetensors'\n",
        "# }\n",
        "\n",
        "frame_count = 25\n",
        "\n",
        "input_path=\"videos/pexels-cottonbro-studio-6649832-960x506-25fps.mp4\"\n",
        "prompt=\"white ancient Greek sculpture, Venus de Milo, light pink and blue background\"\n",
        "image_resolution=512\n",
        "control_strength=0.7\n",
        "color_preserve=True\n",
        "left_crop=0\n",
        "right_crop=180\n",
        "top_crop=0\n",
        "bottom_crop=0\n",
        "control_type=\"canny\"\n",
        "low_threshold=50\n",
        "high_threshold=100\n",
        "ddim_steps=20\n",
        "scale=7.5\n",
        "seed=0\n",
        "sd_model=\"realisticVisionV20_v20\"\n",
        "a_prompt=\"RAW photo, subject, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3\"\n",
        "n_prompt=\"(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, amputation\"\n",
        "interval=1\n",
        "keyframe_count=8#(frame_count - 2) // interval\n",
        "x0_strength=0.95\n",
        "use_constraints=\"shape-aware fusion\"\n",
        "cross_start=0\n",
        "cross_end=1\n",
        "style_update_freq=1\n",
        "warp_start=0\n",
        "warp_end=1\n",
        "mask_start=0.5\n",
        "mask_end=0.8\n",
        "ada_start=0.8\n",
        "ada_end=1\n",
        "mask_strength=0.5\n",
        "inner_strength=0.9\n",
        "smooth_boundary=True\n",
        "\n",
        "input_uploaded(input_path)\n",
        "interval_changed(interval)\n",
        "\n",
        "global video_frame_count\n",
        "video_frame_count = frame_count\n",
        "\n",
        "process(\n",
        "\t*[\n",
        "        # input_path,\n",
        "        prompt,\n",
        "        image_resolution,\n",
        "        control_strength,\n",
        "        color_preserve,\n",
        "        left_crop,\n",
        "        right_crop,\n",
        "        top_crop,\n",
        "        bottom_crop,\n",
        "        control_type,\n",
        "        low_threshold,\n",
        "        high_threshold,\n",
        "        ddim_steps,\n",
        "        scale,\n",
        "        seed,\n",
        "        sd_model,\n",
        "        a_prompt,\n",
        "        n_prompt,\n",
        "        interval,\n",
        "        keyframe_count,\n",
        "        x0_strength,\n",
        "        use_constraints,\n",
        "        cross_start,\n",
        "        cross_end,\n",
        "        style_update_freq,\n",
        "        warp_start,\n",
        "        warp_end,\n",
        "        mask_start,\n",
        "        mask_end,\n",
        "        ada_start,\n",
        "        ada_end,\n",
        "        mask_strength,\n",
        "        inner_strength,\n",
        "        smooth_boundary,\n",
        "\t]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qBWR5mvwACk",
        "outputId": "25593ebd-3ea4-4815-9f1a-385650137cb7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/replicate-rerender\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:23<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:21<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:22<00:00,  1.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:22<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (1, 4, 64, 96), eta 0.0\n",
            "Running DDIM Sampling with 20 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[164,  91, 104],\n",
              "         [172,  88, 105],\n",
              "         [172,  86, 105],\n",
              "         ...,\n",
              "         [ 77, 164, 178],\n",
              "         [ 75, 166, 181],\n",
              "         [ 79, 155, 171]],\n",
              " \n",
              "        [[169,  90, 105],\n",
              "         [173,  86, 105],\n",
              "         [172,  88, 107],\n",
              "         ...,\n",
              "         [ 75, 163, 177],\n",
              "         [ 74, 163, 181],\n",
              "         [ 72, 163, 180]],\n",
              " \n",
              "        [[170,  88, 105],\n",
              "         [173,  89, 105],\n",
              "         [171,  90, 105],\n",
              "         ...,\n",
              "         [ 76, 163, 177],\n",
              "         [ 74, 163, 179],\n",
              "         [ 70, 161, 177]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[181,  94, 137],\n",
              "         [181,  94, 139],\n",
              "         [180,  95, 140],\n",
              "         ...,\n",
              "         [  3, 160, 172],\n",
              "         [  3, 159, 173],\n",
              "         [  3, 158, 176]],\n",
              " \n",
              "        [[179,  94, 134],\n",
              "         [182,  95, 139],\n",
              "         [181,  94, 140],\n",
              "         ...,\n",
              "         [  2, 158, 170],\n",
              "         [  3, 158, 173],\n",
              "         [  6, 152, 173]],\n",
              " \n",
              "        [[171, 101, 129],\n",
              "         [180,  96, 137],\n",
              "         [181,  96, 141],\n",
              "         ...,\n",
              "         [  0, 159, 168],\n",
              "         [  6, 160, 167],\n",
              "         [ 25, 145, 160]]], dtype=uint8),\n",
              " 'result/pexels-cottonbro-studio-6649832-960x506-25fps/key.mp4')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2sOYEskaUG1l"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}